# Инструкция

Для начала Вам необходимо проверить, что следующие программы установлены, а в противном случае их установить:

* **Python 2.7** с установленными пакетами

  * **pip** (в версиях Python 2.7.9 и далее он уже установлен)
  
  * **setuptools** (в версиях Python 2.7.9 и далее он уже установлен)
  
  * **lxml**
  
  * **OpenSSL**
  
  * **scrapy** (его устанавливайте последним - он требует всех других пакетов)
  
* **Midnight Commander** (или любая другая программа, с помощью которой можно безопасно и надёжно обмениваться файлами между локальным компьютером и серверами в Интернете.: **FileZilla**, **CuteFTP** и т.д.)

* **Putty** (для Windows, чтобы подключаться к серверу)

## Установка пакетов в Python 2.7

1. В командной строке дойти до папки Python27\Scripts  с помощью команды **"cd" + путь к папке**

2. Произвести установку с помощью команды **"pip install <package name>"**

3. Чтобы проверить, что пакет установился, можно забить **"pip freeze"**

## Использование Putty

1. Запустите Putty

2. Введите Host Name - в нашем случае **"new_words@web-corpora"**

3. Введите пароль (то, что вводится пароль никак не будет отражаться на экране) и нажмите Enter

4. Вам должно высветиться что-то подобное **"new_words@ubuntu:irl:~$"**, это значит, что Вы подключились к серверу

## Команды на сервере

* **ls** - показывает, где Вы находитесь на сервере в данный момент (какие папки, архивы, файлы там находятся)

* **cd <имя папки или архива>** - заходит в папку или архив

* **nano <имя файла>** - открывает файл

* **.** - путь к той папке, в которой Вы сейчас находитесь (облегчает работу при написании пути)

* **cd ../** - возвращает Вас на папку выше

## Сами краулеры

Сами краулеры лежат в папке **thai_scrapy** данного репозитория. Необходимо скачать **всю папаку "thai_scrapy"** так, чтобы внутрення структура осталась такой же.

Как подстроить краулер под конкретный сайт:

1. Открыть **"thai_spyder"** (путь - "thai_scrapy\thai_scrapy\spiders") 

 1. В этом коде добавить **новый класс**, имеющий вид уже написанных классов. 

 2. В новом, созданном Вами классе, изменить название класса на **"`<name>`Spider"** 

 3. В строчке **"name = '`<name>`'"** изменить старое имя на новое (то, что вы присвоили до слова "Spider" в названии самого класс)

 4. В строчке **"allowed_domains = [u'`<website>`']"** заменить старую ссылку сайта на новую **(без "http://www.")**

 5. В строчке **"start_urls = [u'`<website>`',]"** заменить старую ссылку сайта на новую **(с "http://www." и, если необходимо, с чем-то после слеша)**
 
 6. В конце файла в функции "parse_items" d строчке **"paragraphs = hxs.xpath(u'`<xml>`')"** изменить старый xml-код параграфов на новый. Новый код Вы можете найти на сайте, с которого Вы собираетесь скачивать страницы. Необходимо найти тот код, который содержит в себе большие куски текста, которые Вам и нужны. В Google Chrome это удобно сделать: найти нужный кусок текста на страницы, щелкнуть на правую клавишу мыши и выбрать "Просмотреть код". Справа Вам высветиться код.

 7. В строчке **"title = hxs.xpath(u'`<xml>`')"** изменить старый xml-код названия на новый. Новый код Вы можете найти на сайте, с которого Вы собираетесь скачивать страницы. Необходимо найти тот код, который содержит в себе название текста, который Вы скачиваете. Также удобно сделать в Google Chrome.
 
2. Открыть **"pipelines"** (путь - "thai_scrapy\thai_scrapy")

 1. В этом коде в **"with codecs.open(u'`<website>`' + str(item[u'name'])"** ссылку старого сайта замените на ссылку нового.
 
 2. Если необходимо, измените жанр внутри **"`<genre>` `</genre>`"**
